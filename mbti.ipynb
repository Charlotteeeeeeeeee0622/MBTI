{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NltDyB-KrfSg"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import re\n",
        "import string\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, recall_score, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "import joblib\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import tweepy\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import numpy as np # linear algebra\n",
        "import os # accessing directory structure\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "import wordcloud\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"../mbti_1.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "PKO5gKzBwcsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().any()#Checking if there are any missing or null values present in the dataset."
      ],
      "metadata": {
        "id": "1YW_9dB-wgWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape #The shape of the dataset"
      ],
      "metadata": {
        "id": "Yl0ghnLYwwX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info() #information about dataset"
      ],
      "metadata": {
        "id": "sqO3FolfwzjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "types = np.unique(np.array(df['type']))\n",
        "types"
      ],
      "metadata": {
        "id": "-2ZZqrV5x69u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.type.value_counts())\n",
        "df.type.hist(xrot=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yltV7YSxyFwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = df['type'].value_counts()\n",
        "plt.figure(figsize=(15,6))\n",
        "sb.barplot(graph.index, graph.values, alpha=1)\n",
        "plt.xlabel('Personality types', fontsize=15)\n",
        "plt.ylabel('No. of posts', fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l_-NvSS0yJOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Swarm Plot\n",
        "df1 = df.copy()\n",
        "#this function counts the no of words in each post of a user\n",
        "def var_row(row):\n",
        "    l = []\n",
        "    for i in row.split('|||'):\n",
        "        l.append(len(i.split()))\n",
        "    return np.var(l)\n",
        "\n",
        "#this function counts the no of words per post out of the total 50 posts in the whole row\n",
        "df1['words_per_comment'] = df1['posts'].apply(lambda x: len(x.split())/50)\n",
        "df1['variance_of_word_counts'] = df1['posts'].apply(lambda x: var_row(x))\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "sb.swarmplot(\"type\", \"words_per_comment\", data=df1)"
      ],
      "metadata": {
        "id": "ivRnGQzj0KaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(len(df1['type'].unique()), sharex=True, figsize=(15,len(df1['type'].unique())))\n",
        "k = 0\n",
        "for i in df1['type'].unique():\n",
        "    df_2 = df[df['type'] == i]\n",
        "    wordcloud = WordCloud(max_words=1628,relative_scaling=1,normalize_plurals=False).generate(df_2['posts'].to_string())\n",
        "    plt.subplot(4,4,k+1)\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.title(i)\n",
        "    ax[k].axis(\"off\")\n",
        "    k+=1"
      ],
      "metadata": {
        "id": "ddTOOM1O0M5b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}